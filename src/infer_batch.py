# infer_batch.py
# -----------------------------
# æ‰¹é‡æ¨ç†æ¨¡å—ï¼šä½¿ç”¨è®­ç»ƒå¥½çš„ YOLOv8 æ¨¡å‹å¯¹å›¾ç‰‡è¿›è¡Œæ£€æµ‹
# å¹¶æŒ‰ç±»åˆ«ï¼ˆhuman/animal/landscapeï¼‰ä¿å­˜ç»“æœ
# -----------------------------

import os
from pathlib import Path
import cv2
from ultralytics import YOLO
from tqdm import tqdm

def ensure_dir(path):
    """ç¡®ä¿ç›®å½•å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»º"""
    Path(path).mkdir(parents=True, exist_ok=True)

def save_results_txt(results, save_txt_path):
    """ä¿å­˜ YOLO æ£€æµ‹ç»“æœåˆ° txt æ–‡ä»¶"""
    with open(save_txt_path, 'w', encoding='utf-8') as f:
        for box in results.boxes:
            cls_id = int(box.cls.cpu().numpy()[0])
            conf = float(box.conf.cpu().numpy()[0])
            x_center = float(box.xywhn[0][0].cpu().numpy())
            y_center = float(box.xywhn[0][1].cpu().numpy())
            w = float(box.xywhn[0][2].cpu().numpy())
            h = float(box.xywhn[0][3].cpu().numpy())
            f.write(f"{cls_id} {conf:.4f} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\n")

def batch_infer(model_path, names, human_classes, animal_classes, landscape_classes, infer_cfg, device):
    """
    æ‰¹é‡æ¨ç†å…¥å£
    å‚æ•°ï¼š
        model_path      -> è®­ç»ƒå¥½çš„ best.pt æ¨¡å‹è·¯å¾„
        names           -> ç±»åˆ«ID -> åç§°æ˜ å°„å­—å…¸
        human_classes   -> äººç±»ç±»åˆ«IDé›†åˆ
        animal_classes  -> åŠ¨ç‰©ç±»åˆ«IDé›†åˆ
        landscape_classes -> é£æ™¯/æ— ç›®æ ‡ç±»åˆ«IDé›†åˆ
        infer_cfg       -> æ¨ç†é…ç½®å­—å…¸ï¼ŒåŒ…æ‹¬è¾“å…¥/è¾“å‡ºè·¯å¾„ã€ç½®ä¿¡åº¦é˜ˆå€¼ç­‰
        device          -> æ¨ç†è®¾å¤‡ï¼ŒGPUæˆ–CPU
    """

    print("\nğŸ” å¼€å§‹æ‰¹é‡æ£€æµ‹å›¾ç‰‡...")

    # æ¨ç†å‚æ•°
    input_dir = Path(infer_cfg.get('input_dir', './images'))
    output_dir = Path(infer_cfg.get('output_dir', './results'))
    conf_threshold = infer_cfg.get('conf_threshold', 0.25)
    draw_boxes = infer_cfg.get('draw_boxes', True)

    # åˆ›å»ºè¾“å‡ºç›®å½•å’Œå­ç›®å½•
    ensure_dir(output_dir)
    human_dir = output_dir / "human"
    animal_dir = output_dir / "animal"
    landscape_dir = output_dir / "landscape"
    for d in [human_dir, animal_dir, landscape_dir]:
        ensure_dir(d)

    # åŠ è½½æ¨¡å‹
    model = YOLO(model_path)

    # è·å–å›¾ç‰‡åˆ—è¡¨
    image_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]
    print(f"æ£€æµ‹åˆ° {len(image_files)} å¼ å›¾ç‰‡")

    # è¯†åˆ«ç»“æœæ±‡æ€»
    summary_path = output_dir / "è¯†åˆ«ç»“æœ.txt"
    with open(summary_path, 'w', encoding='utf-8') as summary_file:
        for img_name in tqdm(image_files, desc="æ‰¹é‡æ£€æµ‹ä¸­"):
            img_path = input_dir / img_name

            # YOLOæ¨ç†
            results = model.predict(str(img_path), conf=conf_threshold, device=device, verbose=False)
            r = results[0]
            r.names = names

            # ç»Ÿè®¡æ¯ç±»æœ€é«˜ç½®ä¿¡åº¦ & æ£€æµ‹åˆ°çš„ç±»åˆ«
            confidences = {}
            detected_cls = set()
            for box in r.boxes:
                cls_id = int(box.cls.cpu().numpy()[0])
                conf = float(box.conf.cpu().numpy()[0])
                detected_cls.add(cls_id)
                if cls_id not in confidences or conf > confidences[cls_id]:
                    confidences[cls_id] = conf

            # æ ¹æ®ç±»åˆ«åˆ†ç›®å½•
            if len(detected_cls) == 0:
                save_dir_target = landscape_dir
            elif detected_cls & human_classes:
                save_dir_target = human_dir
            elif detected_cls & animal_classes:
                save_dir_target = animal_dir
            else:
                save_dir_target = landscape_dir

            # è¾“å‡ºå›¾ç‰‡è·¯å¾„å’Œ txt è·¯å¾„
            save_img_path = save_dir_target / img_name
            save_txt_path = save_img_path.with_suffix(".txt")

            # ä¿å­˜å¸¦æ£€æµ‹æ¡†çš„å›¾ç‰‡
            if draw_boxes:
                annotated_img = r.plot()
                annotated_img = cv2.cvtColor(annotated_img, cv2.COLOR_RGB2BGR)
            else:
                annotated_img = cv2.imread(str(img_path))
            cv2.imwrite(str(save_img_path), annotated_img)

            # ä¿å­˜æ£€æµ‹æ¡†ä¿¡æ¯
            save_results_txt(r, save_txt_path)

            # ç”Ÿæˆç‰©ç§è¯†åˆ«æè¿°
            species_list = [f"{names[cid]}: ç½®ä¿¡åº¦{int(confidences[cid]*100)}%" for cid in confidences]
            species_str = "ï¼› ".join(species_list) if species_list else "æ— æ£€æµ‹ç›®æ ‡"

            # è®°å½•æ±‡æ€»æ–‡ä»¶
            rel_save_path = os.path.relpath(save_img_path, output_dir).replace("\\", "/")
            summary_file.write(f"åŸç…§ç‰‡: {img_name}, è¯†åˆ«ç…§ç‰‡: {rel_save_path}, è¯†åˆ«ç‰©ç§: {species_str}\n")

    print(f"\nâœ… æ‰¹é‡æ¨ç†å®Œæˆï¼Œç»“æœä¿å­˜åœ¨ï¼š{output_dir}")
