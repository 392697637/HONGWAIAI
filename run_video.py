# run_video.py
from pathlib import Path
from src.utils import ensure_dir, find_best_pt
from ultralytics import YOLO
import cv2

# ---------------- é…ç½® ----------------
input_video_path = Path("./dataset/videos/sample.mp4")  # è¾“å…¥è§†é¢‘
output_dir = Path("./results/videos")                  # è¾“å‡ºç›®å½•
conf_threshold = 0.25                                  # ç½®ä¿¡åº¦é˜ˆå€¼
draw_boxes = True                                      # æ˜¯å¦ç»˜åˆ¶æ¡†

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
ensure_dir(output_dir)

# è‡ªåŠ¨æ‰¾åˆ°æœ€æ–° best.pt
best_model_path = find_best_pt("./models")
print(f"âœ… ä½¿ç”¨æ¨¡å‹: {best_model_path}")

# åŠ è½½æ¨¡å‹
model = YOLO(best_model_path)

# æ‰“å¼€è§†é¢‘
cap = cv2.VideoCapture(str(input_video_path))
if not cap.isOpened():
    raise FileNotFoundError(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘: {input_video_path}")

width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps = cap.get(cv2.CAP_PROP_FPS)

output_video_path = output_dir / f"{input_video_path.stem}_out.mp4"
fourcc = cv2.VideoWriter_fourcc(*"mp4v")
out = cv2.VideoWriter(str(output_video_path), fourcc, fps, (width, height))

print("ğŸš€ å¼€å§‹è§†é¢‘æ¨ç†...")

frame_count = 0
while True:
    ret, frame = cap.read()
    if not ret:
        break
    frame_count += 1

    results = model.predict(frame, conf=conf_threshold, verbose=False)[0]

    if draw_boxes:
        annotated_frame = results.plot()
        annotated_frame = cv2.cvtColor(annotated_frame, cv2.COLOR_RGB2BGR)
    else:
        annotated_frame = frame

    out.write(annotated_frame)

cap.release()
out.release()
print(f"âœ… è§†é¢‘æ¨ç†å®Œæˆï¼Œç»“æœä¿å­˜åœ¨: {output_video_path}, æ€»å¸§æ•°: {frame_count}")
